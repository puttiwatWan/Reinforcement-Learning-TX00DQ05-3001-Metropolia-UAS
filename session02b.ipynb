{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TX00DQ05-3001 Exercises 2\n",
    "\n",
    "Note that you don't have to use the functions / other code in the cells below. They are there just in case you need inspiration to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n",
    "import numpy.linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Iterative policy evaluation. \n",
    "\n",
    "Calculate state-value function V for the gridworld of Sutton & Barto example 4.1. Policy is assumed to be random, ie. each of the four directions are equally likely. Movement that would result in leaving the grid (for example moving up in top row) will leave state unchanged (but action has been taken). Gamma (discount factor) is assumed to be = 1, ie. no discounting.\n",
    "\n",
    "When norm of the difference between new V and the old one is less than eps, stop iteration.\n",
    "\n",
    "Compare needed number of iterations between synchronous (sweep over all states, and update value function after the sweep) and asynchronous (use always the latest values) update of state-value function.\n",
    "\n",
    "Note that numpy tensor assignment does not create a copy. You might want to use .copy() method to avoid sharing a reference to the same array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_count = 4\n",
    "columns_count = 4\n",
    "\n",
    "terminating = [(0,0), (rows_count-1, columns_count-1)]\n",
    "\n",
    "stepcost = -1\n",
    "prob_up = 0.25\n",
    "prob_left = 0.25\n",
    "prob_right = 0.25\n",
    "prob_down = 0.25\n",
    "\n",
    "maxiters = 1000\n",
    "eps = 0.0000001\n",
    "\n",
    "step_up = -1\n",
    "step_down = -1\n",
    "step_left = -1\n",
    "step_right = -1\n",
    "\n",
    "def valueFor(row, column, direction):\n",
    "    # YOUR CODE HERE\n",
    "    if direction == '↑':\n",
    "        row -= 1\n",
    "        if row < 0:\n",
    "            row = 0\n",
    "    elif direction == '←':\n",
    "        column -= 1\n",
    "        if column < 0:\n",
    "            column = 0\n",
    "    elif direction == '→':\n",
    "        column += 1\n",
    "        if column >= columns_count:\n",
    "            column = columns_count-1\n",
    "    elif direction == '↓':\n",
    "        row += 1\n",
    "        if row >= rows_count:\n",
    "            row = rows_count-1\n",
    "    return V[row, column]\n",
    "\n",
    "def calculateValue(row, column):\n",
    "    up = valueFor(row,column,'↑')\n",
    "    left = valueFor(row,column,'←')\n",
    "    right = valueFor(row,column,'→')\n",
    "    down = valueFor(row,column,'↓')\n",
    "    val = prob_up*(step_up+up) + prob_left*(step_left+left) + prob_right*(step_right+right) + prob_down*(step_down+down)\n",
    "    return val\n",
    "\n",
    "def resetMatrix():\n",
    "    return np.zeros((rows_count, columns_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synchronous Iteration: 319\n",
      "[[  0. -14. -20. -22.]\n",
      " [-14. -18. -20. -20.]\n",
      " [-20. -20. -18. -14.]\n",
      " [-22. -20. -14.   0.]]\n",
      "Asynchronous Iteration: 205\n",
      "[[  0. -14. -20. -22.]\n",
      " [-14. -18. -20. -20.]\n",
      " [-20. -20. -18. -14.]\n",
      " [-22. -20. -14.   0.]]\n"
     ]
    }
   ],
   "source": [
    "def forExercise1(sync):\n",
    "    global V, V_new\n",
    "    for i in range(maxiters):\n",
    "    # YOUR CODE HERE\n",
    "        if sync:\n",
    "            V = V_new.copy()\n",
    "        else:\n",
    "            V = V_new\n",
    "            #V is assigned to the same pointer as V_new, technically the same variables pointing to the same data\n",
    "        norm = LA.norm(V)\n",
    "        for r in range(rows_count):\n",
    "            for c in range(columns_count):\n",
    "                if not (r,c) in terminating:\n",
    "                    V_new[r,c] = calculateValue(r,c)    \n",
    "        new_norm = LA.norm(V_new)\n",
    "        if np.absolute(new_norm - norm) <= eps:\n",
    "            break\n",
    "    if sync:\n",
    "        print(\"Synchronous Iteration:\", i)\n",
    "    else:\n",
    "        print(\"Asynchronous Iteration:\", i)\n",
    "    with np.printoptions(precision=3):\n",
    "        print(V)\n",
    "    return\n",
    "\n",
    "V = resetMatrix()\n",
    "V_new = resetMatrix()\n",
    "forExercise1(sync=True)\n",
    "\n",
    "V = resetMatrix()\n",
    "V_new = resetMatrix()\n",
    "forExercise1(sync=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Greedy policy. \n",
    "\n",
    "Based on the state-value function computed in exercise 1, print out deterministic greedy policy function. Is the policy generated also optimal one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0. -14. -20. -22.]\n",
      " [-14. -18. -20. -20.]\n",
      " [-20. -20. -18. -14.]\n",
      " [-22. -20. -14.   0.]]\n",
      "['T', '←', '←', '←']\n",
      "['↑', '←', '←', '↓']\n",
      "['↑', '↑', '↓→', '↓']\n",
      "['↑', '→', '→', 'T']\n",
      "The policy is optimal. It goes through the highest-reward path.\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# ←↑↓→\n",
    "def greedy(row, column):\n",
    "    up = valueFor(row,column,'↑')\n",
    "    left = valueFor(row,column,'←')\n",
    "    right = valueFor(row,column,'→')\n",
    "    down = valueFor(row,column,'↓')\n",
    "    num_list = [up + step_up, left + step_left, right + step_right, down + step_down]\n",
    "    max_val = max(num_list)\n",
    "    directions = ''\n",
    "    \n",
    "    if left+step_left == max_val:\n",
    "        directions += '←'\n",
    "    if up+step_up == max_val:\n",
    "        directions += '↑'\n",
    "    if down+step_down == max_val:\n",
    "        directions += '↓'\n",
    "    if right+step_right == max_val:\n",
    "        directions += '→'\n",
    "    \n",
    "    return directions\n",
    "\n",
    "def calculatePolicy():\n",
    "    global policy\n",
    "    policy = []\n",
    "    for r in range(rows_count):\n",
    "        policy.append([])\n",
    "        for c in range(columns_count):\n",
    "            if not (r,c) in terminating:\n",
    "                policy[r].append(greedy(r,c))\n",
    "            else:\n",
    "                policy[r].append('T')\n",
    "    return\n",
    "\n",
    "#Initiate policy\n",
    "policy = []\n",
    "for i in range(rows_count):\n",
    "    policy.append([])\n",
    "    \n",
    "calculatePolicy()\n",
    "\n",
    "with np.printoptions(precision=3):\n",
    "    print(V)\n",
    "\n",
    "for item in policy:\n",
    "    print(item)\n",
    "    \n",
    "print(\"The policy is optimal. It goes through the highest-reward path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.99999978120095\n",
      "-13.999999781200952\n",
      "←\n"
     ]
    }
   ],
   "source": [
    "#Check why is there only one arrow\n",
    "print(V[1][0])\n",
    "print(V[0][1])\n",
    "print(policy[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Value function and policy in modified gridworld.\n",
    "\n",
    "Change the definition of the exercise 1 gridworld by assigning a cost of -8 to movement in \"up\" direction. Compute the value function and greedy policy based on the value function. Is the greedy policy optimal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration (Asynchronous): 216\n",
      "[[  0.  -38.5 -55.  -60.5]\n",
      " [-38.5 -49.5 -55.  -55. ]\n",
      " [-55.  -55.  -49.5 -38.5]\n",
      " [-60.5 -55.  -38.5   0. ]]\n",
      "['T', '←', '←', '←']\n",
      "['↑', '←', '←', '↓']\n",
      "['↑', '→', '↓→', '↓']\n",
      "['→', '→', '→', 'T']\n",
      "The policy is not optimal since [0,2] should go right and/or down instead (because of -8 cost for going up).\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "V = resetMatrix()\n",
    "V_new = resetMatrix()\n",
    "\n",
    "step_up = -8\n",
    "\n",
    "for i in range(maxiters):\n",
    "# YOUR CODE HERE\n",
    "    V = V_new\n",
    "    norm = LA.norm(V)\n",
    "    for r in range(rows_count):\n",
    "        for c in range(columns_count):\n",
    "            if not (r,c) in terminating:\n",
    "                V_new[r,c] = calculateValue(r,c)\n",
    "    new_norm = LA.norm(V_new)\n",
    "    if np.absolute(new_norm - norm) <= eps:\n",
    "        break\n",
    "\n",
    "calculatePolicy()\n",
    "\n",
    "print(\"Iteration (Asynchronous):\", i)\n",
    "with np.printoptions(precision=3):\n",
    "    print(V)\n",
    "for item in policy:\n",
    "    print(item)\n",
    "    \n",
    "print(\"The policy is not optimal since [0,2] should go right and/or down instead (because of -8 cost for going up).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra exercise: Policy iteration\n",
    "\n",
    "Implement policy iteration, ie. create a policy with the help of the value function from previous policy and iterate until policy is stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-5. -4. -3. -2.]\n",
      " [-4. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "['T', '←', '←', '←↓']\n",
      "['↓→', '↓→', '↓→', '↓']\n",
      "['↓→', '↓→', '↓→', '↓']\n",
      "['→', '→', '→', 'T']\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# ←↑↓→\n",
    "import copy\n",
    "\n",
    "prob_up = 0\n",
    "prob_left = 0\n",
    "prob_right = 0\n",
    "prob_down = 0\n",
    "theta = 0.0000001\n",
    "\n",
    "def calculateProb(direction):\n",
    "    prob = 1/len(direction)\n",
    "    global prob_left, prob_right, prob_up, prob_down\n",
    "    if '←' in direction:\n",
    "        prob_left = prob\n",
    "    if '↑' in direction:\n",
    "        prob_up = prob\n",
    "    if '↓' in direction:\n",
    "        prob_down = prob\n",
    "    if '→' in direction:\n",
    "        prob_right = prob\n",
    "    return\n",
    "\n",
    "def clearProb():\n",
    "    global prob_left, prob_right, prob_up, prob_down\n",
    "    prob_left = 0\n",
    "    prob_right = 0\n",
    "    prob_up = 0\n",
    "    prob_down = 0\n",
    "    return\n",
    "\n",
    "for loop in range(maxiters):\n",
    "    for i in range(maxiters):\n",
    "        delta = 0\n",
    "        for r in range(rows_count):\n",
    "            for c in range(columns_count):\n",
    "                if not (r,c) in terminating:\n",
    "                    calculateProb(policy[r][c])\n",
    "                    val = calculateValue(r,c)\n",
    "                    clearProb()\n",
    "                    if delta < np.absolute(V[r,c] - val):\n",
    "                        delta = np.absolute(V[r,c] - val)\n",
    "                    V_new[r,c] = val\n",
    "        V = V_new\n",
    "        if delta < theta:\n",
    "            break\n",
    "    \n",
    "    #find new policy\n",
    "    old_policy = copy.deepcopy(policy)\n",
    "    calculatePolicy()\n",
    "    if policy == old_policy:\n",
    "        break\n",
    "        \n",
    "print('Iteration:',loop)\n",
    "print(V)\n",
    "for i in policy:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Value iteration\n",
    "\n",
    "Solve the exercise 1 gridworld with value iteration algorithm. Solve also modified gridworld (cost of \"up\" movement = -4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 3\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "Iterations: 4\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-4. -4. -3. -2.]\n",
      " [-4. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# value iteration\n",
    "# ←↑↓→\n",
    "theta = 0.0001\n",
    "maxiters = 10\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def forExercise4(step_up_value):\n",
    "    global V, step_up\n",
    "    step_up = step_up_value\n",
    "    for i in range(maxiters):\n",
    "        delta = 0\n",
    "        for r in range(rows_count):\n",
    "            for c in range(columns_count):\n",
    "                if not (r, c) in terminating:\n",
    "                    direction = greedy(r,c)\n",
    "                    calculateProb(direction[0])\n",
    "                    val = calculateValue(r,c)\n",
    "                    clearProb()\n",
    "                    if delta < np.absolute(V[r,c] - val):\n",
    "                        delta = np.absolute(V[r,c] - val)\n",
    "                    V[r,c] = val\n",
    "        if delta < theta:\n",
    "            break\n",
    "    \n",
    "    print('Iterations:',i)\n",
    "    with np.printoptions(precision=3):\n",
    "        print(V)\n",
    "\n",
    "    return\n",
    "\n",
    "V = resetMatrix()\n",
    "forExercise4(step_up_value = -1)\n",
    "\n",
    "V = resetMatrix()\n",
    "forExercise4(step_up_value = -4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
